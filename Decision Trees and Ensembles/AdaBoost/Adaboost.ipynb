{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61mBqcAMSdD-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib import style\n",
        "style.use('fivethirtyeight')\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ionosphere = pd.read_csv('Ionosphere.txt', header=None)\n",
        "Ionosphere.iloc[:,-1] = np.where(Ionosphere.iloc[:,-1] == 'g',1,-1)"
      ],
      "metadata": {
        "id": "Jla1DNzuiASp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ionosphere)"
      ],
      "metadata": {
        "id": "HdPCeIb5iAYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "weak_tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)"
      ],
      "metadata": {
        "id": "9Ea8S_4jiAaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Ionosphere.iloc[:, :-1], Ionosphere.iloc[:, -1], test_size = 0.3, shuffle=True)\n",
        "weak_tree.fit(X_train, y_train)\n",
        "y_pred = weak_tree.predict(X_test)\n",
        "Ionosphere_before = accuracy_score(y_test, y_pred) * 100\n",
        "print(\"%.2f%% For Ionosphere\" %Ionosphere_before)"
      ],
      "metadata": {
        "id": "mQA2XA5tiAc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Boosting:\n",
        "\n",
        "    def __init__(self,dataset,T,test_dataset):\n",
        "        self.dataset = dataset\n",
        "        self.T = T\n",
        "        self.test_dataset = test_dataset\n",
        "        self.alphas = None\n",
        "        self.models = None\n",
        "        self.accuracy = []\n",
        "        self.predictions = None\n",
        "    \n",
        "    def myfit(self):\n",
        "\n",
        "        X = self.dataset.iloc[:, :-1]\n",
        "        Y = self.dataset.iloc[:, -1]\n",
        "\n",
        "        Evaluation = pd.DataFrame(Y.copy())\n",
        "        Evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N\n",
        "        \n",
        "        \n",
        "        alphas = [] \n",
        "        models = []\n",
        "        \n",
        "        for t in range(self.T):\n",
        "\n",
        "            # Train the weak tree model classifiers\n",
        "            weak_tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\n",
        "            \n",
        "            model = weak_tree.fit(X,Y,sample_weight=np.array(Evaluation['weights'])) \n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "            Evaluation['predictions'] = model.predict(X)\n",
        "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation.iloc[:,0],1,0)\n",
        "\n",
        "           \n",
        "            misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
        "\n",
        "            err = np.sum(Evaluation['weights']*Evaluation['misclassified'])\n",
        "  \n",
        "            alpha = np.log((1-err)/err)/2\n",
        "            alphas.append(alpha)\n",
        "\n",
        "            Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n",
        "            Evaluation['weights'] = Evaluation['weights'] / np.sum(Evaluation['weights'])\n",
        "\n",
        "        \n",
        "        self.alphas = alphas\n",
        "        self.models = models\n",
        "            \n",
        "    def mypredict(self):\n",
        "\n",
        "        X_test = self.test_dataset.iloc[:, :-1]\n",
        "        Y_test = self.test_dataset.iloc[:, -1]\n",
        "\n",
        "        accuracy = []\n",
        "        predictions = []\n",
        "        \n",
        "        for alpha,model in zip(self.alphas,self.models):\n",
        "            prediction = alpha*model.predict(X_test)\n",
        "            predictions.append(prediction)\n",
        "            self.accuracy.append(np.sum( np.sign(np.sum(np.array(predictions),axis=0)) == Y_test.values )/len(predictions[0]))\n",
        " \n",
        "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))"
      ],
      "metadata": {
        "id": "yxXbPt6oiAf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addNoise(dataset,n):\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size = 0.3, shuffle=True)\n",
        "  cols = [i for i in range(len(dataset.columns)-1)]\n",
        "  list_of_random_items = random.sample(cols, math.ceil((len(dataset.columns)-1) * n/100))\n",
        "  noise = X_train.iloc[:, list_of_random_items] + np.random.normal( 0,1, X_train.iloc[:, list_of_random_items].shape )\n",
        "  X_train.iloc[:,list_of_random_items] = noise\n",
        "\n",
        "  return X_train, X_test,y_train,y_test"
      ],
      "metadata": {
        "id": "MbSq7COxiAic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for Ionosphere dataset with a weak learner was %.2f%%' %Ionosphere_before)\n",
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax0 = fig.add_subplot(111)\n",
        "\n",
        "fig1 = plt.figure(figsize=(6,6))\n",
        "ax1 = fig1.add_subplot(111)\n",
        "\n",
        "for T in AdaBoost_T:\n",
        "  accuracy = []\n",
        "  for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(Ionosphere.iloc[:, :-1], Ionosphere.iloc[:, -1], test_size = 0.3, shuffle=True)\n",
        "    train_Ionosphere = pd.concat([X_train, y_train], axis =1)\n",
        "    test_Ionosphere = pd.concat([X_test, y_test], axis =1)\n",
        "\n",
        "    model = Boosting(train_Ionosphere,T,test_Ionosphere)\n",
        "    \n",
        "    model.myfit()\n",
        "    model.mypredict()\n",
        "    accuracy.append(model.accuracy[-1])\n",
        "\n",
        "  ax1.plot(range(len(model.accuracy)),model.accuracy,label=T)\n",
        "\n",
        "  ax0.plot(range(len(accuracy)),accuracy,label=T)\n",
        "  print('Accuracy for T = ' ,T ,': %.2f %% (Ionosphere Dataset)' %(np.mean(accuracy)*100) )\n",
        "\n",
        "\n",
        "ax0.legend()\n",
        "ax0.set_xlabel('number of Rounds')\n",
        "ax0.set_ylabel('accuracy')\n",
        "ax0.set_title('Ionosphere accuracy for T = 21,31,41,51 in 10 runs')    \n",
        "\n",
        "ax1.legend()\n",
        "ax1.set_xlabel('number of models used for Boosting')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax1.set_title('Ionosphere accuracy for T = 21,31,41,51')   \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "loeUbdr8iAkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Noises = [10,20,30]\n",
        "print('-'*70)\n",
        "for n in Noises:\n",
        "  X_train, X_test, y_train, y_test = addNoise(Ionosphere,n)\n",
        "  weak_tree.fit(X_train, y_train)\n",
        "  predict = weak_tree.predict(X_test)\n",
        "  I_before_with_noise = accuracy_score(y_test, predict) * 100\n",
        "  print('\\n\\t\\t',n,'%% Noisy Ionosphere (before : %.2f%%)' %I_before_with_noise)\n",
        "  for T in AdaBoost_T:\n",
        "    accuracy = []\n",
        "    for i in range(10):\n",
        "      X_train, X_test, y_train, y_test = addNoise(Ionosphere,n)\n",
        "      train_I_noisy = pd.concat([X_train, y_train], axis =1)\n",
        "      test_I_noisy = pd.concat([X_test, y_test], axis =1)\n",
        "\n",
        "      model = Boosting(train_I_noisy,T,test_I_noisy)\n",
        "      model.myfit()\n",
        "      model.mypredict()\n",
        "      accuracy.append(model.accuracy[-1])\n",
        "\n",
        "    print('\\t\\t\\tAccuracy for T =' ,T ,': %.2f %%' %(np.mean(accuracy)*100) )"
      ],
      "metadata": {
        "id": "yYbXqn6SiAnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTM3urk8iAp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hekJQoiPiAsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hboekl0MiAvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LcTMPTIyiAxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}